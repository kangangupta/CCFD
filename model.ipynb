{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import union_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('./train_transaction.csv')\n",
    "d2 = pd.read_csv('./train_identity.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = pd.read_csv('./test_transaction.csv')\n",
    "d4 = pd.read_csv('./test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d1\n",
    "df = df.join(d2,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = d3\n",
    "dft = dft.join(d4,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID_left</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>18403224</td>\n",
       "      <td>31.950</td>\n",
       "      <td>W</td>\n",
       "      <td>10409</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>18403263</td>\n",
       "      <td>49.000</td>\n",
       "      <td>W</td>\n",
       "      <td>4272</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1280x720</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>LGLS676 Build/MXB48T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>18403310</td>\n",
       "      <td>171.000</td>\n",
       "      <td>W</td>\n",
       "      <td>4476</td>\n",
       "      <td>574.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>ie 11.0 for tablet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Trident/7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>18403310</td>\n",
       "      <td>284.950</td>\n",
       "      <td>W</td>\n",
       "      <td>10989</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>18403317</td>\n",
       "      <td>67.950</td>\n",
       "      <td>W</td>\n",
       "      <td>18018</td>\n",
       "      <td>452.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SM-G9650 Build/R16NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506686</th>\n",
       "      <td>4170235</td>\n",
       "      <td>34214279</td>\n",
       "      <td>94.679</td>\n",
       "      <td>C</td>\n",
       "      <td>13832</td>\n",
       "      <td>375.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506687</th>\n",
       "      <td>4170236</td>\n",
       "      <td>34214287</td>\n",
       "      <td>12.173</td>\n",
       "      <td>C</td>\n",
       "      <td>3154</td>\n",
       "      <td>408.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506688</th>\n",
       "      <td>4170237</td>\n",
       "      <td>34214326</td>\n",
       "      <td>49.000</td>\n",
       "      <td>W</td>\n",
       "      <td>16661</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506689</th>\n",
       "      <td>4170238</td>\n",
       "      <td>34214337</td>\n",
       "      <td>202.000</td>\n",
       "      <td>W</td>\n",
       "      <td>16621</td>\n",
       "      <td>516.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506690</th>\n",
       "      <td>4170239</td>\n",
       "      <td>34214345</td>\n",
       "      <td>24.346</td>\n",
       "      <td>C</td>\n",
       "      <td>5713</td>\n",
       "      <td>168.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>147.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506691 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID_left  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0                  3663549       18403224          31.950         W  10409   \n",
       "1                  3663550       18403263          49.000         W   4272   \n",
       "2                  3663551       18403310         171.000         W   4476   \n",
       "3                  3663552       18403310         284.950         W  10989   \n",
       "4                  3663553       18403317          67.950         W  18018   \n",
       "...                    ...            ...             ...       ...    ...   \n",
       "506686             4170235       34214279          94.679         C  13832   \n",
       "506687             4170236       34214287          12.173         C   3154   \n",
       "506688             4170237       34214326          49.000         W  16661   \n",
       "506689             4170238       34214337         202.000         W  16621   \n",
       "506690             4170239       34214345          24.346         C   5713   \n",
       "\n",
       "        card2  card3       card4  card5   card6  ...                    id_31  \\\n",
       "0       111.0  150.0        visa  226.0   debit  ...  chrome 67.0 for android   \n",
       "1       111.0  150.0        visa  226.0   debit  ...  chrome 67.0 for android   \n",
       "2       574.0  150.0        visa  226.0   debit  ...       ie 11.0 for tablet   \n",
       "3       360.0  150.0        visa  166.0   debit  ...  chrome 67.0 for android   \n",
       "4       452.0  150.0  mastercard  117.0   debit  ...  chrome 67.0 for android   \n",
       "...       ...    ...         ...    ...     ...  ...                      ...   \n",
       "506686  375.0  185.0  mastercard  224.0   debit  ...                      NaN   \n",
       "506687  408.0  185.0  mastercard  224.0   debit  ...                      NaN   \n",
       "506688  490.0  150.0        visa  226.0   debit  ...                      NaN   \n",
       "506689  516.0  150.0  mastercard  224.0   debit  ...                      NaN   \n",
       "506690  168.0  144.0        visa  147.0  credit  ...                      NaN   \n",
       "\n",
       "        id_32     id_33           id_34 id_35 id_36  id_37  id_38  DeviceType  \\\n",
       "0         NaN       NaN             NaN     F     F      T      F      mobile   \n",
       "1        24.0  1280x720  match_status:2     T     F      T      T      mobile   \n",
       "2         NaN       NaN             NaN     F     T      T      F     desktop   \n",
       "3         NaN       NaN             NaN     F     F      T      F      mobile   \n",
       "4         NaN       NaN             NaN     F     F      T      F      mobile   \n",
       "...       ...       ...             ...   ...   ...    ...    ...         ...   \n",
       "506686    NaN       NaN             NaN   NaN   NaN    NaN    NaN         NaN   \n",
       "506687    NaN       NaN             NaN   NaN   NaN    NaN    NaN         NaN   \n",
       "506688    NaN       NaN             NaN   NaN   NaN    NaN    NaN         NaN   \n",
       "506689    NaN       NaN             NaN   NaN   NaN    NaN    NaN         NaN   \n",
       "506690    NaN       NaN             NaN   NaN   NaN    NaN    NaN         NaN   \n",
       "\n",
       "                         DeviceInfo  \n",
       "0       MYA-L13 Build/HUAWEIMYA-L13  \n",
       "1              LGLS676 Build/MXB48T  \n",
       "2                       Trident/7.0  \n",
       "3       MYA-L13 Build/HUAWEIMYA-L13  \n",
       "4              SM-G9650 Build/R16NW  \n",
       "...                             ...  \n",
       "506686                          NaN  \n",
       "506687                          NaN  \n",
       "506688                          NaN  \n",
       "506689                          NaN  \n",
       "506690                          NaN  \n",
       "\n",
       "[506691 rows x 434 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in dft.columns:\n",
    "    if '-' in i:\n",
    "        j = '_'.join(i.split('-'))\n",
    "        dft.rename(columns={i:j}, inplace=True)\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']\n"
     ]
    }
   ],
   "source": [
    "categorical_val = []\n",
    "for i in df:\n",
    "    if df[i].dtype=='object':\n",
    "        categorical_val.append(i)\n",
    "\n",
    "print(categorical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_val] = df[categorical_val].astype('category')\n",
    "df[categorical_val] = df[categorical_val].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ProductCD',\n",
       " 'card4',\n",
       " 'card6',\n",
       " 'P_emaildomain',\n",
       " 'R_emaildomain',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'id_12',\n",
       " 'id_15',\n",
       " 'id_16',\n",
       " 'id_23',\n",
       " 'id_27',\n",
       " 'id_28',\n",
       " 'id_29',\n",
       " 'id_30',\n",
       " 'id_31',\n",
       " 'id_33',\n",
       " 'id_34',\n",
       " 'id_35',\n",
       " 'id_36',\n",
       " 'id_37',\n",
       " 'id_38',\n",
       " 'DeviceType',\n",
       " 'DeviceInfo']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[categorical_val] = dft[categorical_val].astype('category')\n",
    "dft[categorical_val] = dft[categorical_val].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID_left</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>4</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>32.0</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590535</th>\n",
       "      <td>3577535</td>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>4</td>\n",
       "      <td>6550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590536</th>\n",
       "      <td>3577536</td>\n",
       "      <td>0</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>4</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590537</th>\n",
       "      <td>3577537</td>\n",
       "      <td>0</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>4</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590538</th>\n",
       "      <td>3577538</td>\n",
       "      <td>0</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>4</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590539</th>\n",
       "      <td>3577539</td>\n",
       "      <td>0</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>4</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID_left  isFraud  TransactionDT  TransactionAmt  ProductCD  \\\n",
       "0                  2987000        0          86400           68.50          4   \n",
       "1                  2987001        0          86401           29.00          4   \n",
       "2                  2987002        0          86469           59.00          4   \n",
       "3                  2987003        0          86499           50.00          4   \n",
       "4                  2987004        0          86506           50.00          1   \n",
       "...                    ...      ...            ...             ...        ...   \n",
       "590535             3577535        0       15811047           49.00          4   \n",
       "590536             3577536        0       15811049           39.50          4   \n",
       "590537             3577537        0       15811079           30.95          4   \n",
       "590538             3577538        0       15811088          117.00          4   \n",
       "590539             3577539        0       15811131          279.95          4   \n",
       "\n",
       "        card1  card2  card3  card4  card5  ...  id_31  id_32  id_33  id_34  \\\n",
       "0       13926    NaN  150.0      1  142.0  ...    123   32.0    164      3   \n",
       "1        2755  404.0  150.0      2  102.0  ...     98   32.0     48      2   \n",
       "2        4663  490.0  150.0      3  166.0  ...     44    NaN     -1     -1   \n",
       "3       18132  567.0  150.0      2  117.0  ...     44    NaN     -1     -1   \n",
       "4        4497  514.0  150.0      2  102.0  ...     44   24.0     40      3   \n",
       "...       ...    ...    ...    ...    ...  ...    ...    ...    ...    ...   \n",
       "590535   6550    NaN  150.0      3  226.0  ...     -1    NaN     -1     -1   \n",
       "590536  10444  225.0  150.0      2  224.0  ...     -1    NaN     -1     -1   \n",
       "590537  12037  595.0  150.0      2  224.0  ...     -1    NaN     -1     -1   \n",
       "590538   7826  481.0  150.0      2  224.0  ...     -1    NaN     -1     -1   \n",
       "590539  15066  170.0  150.0      2  102.0  ...     -1    NaN     -1     -1   \n",
       "\n",
       "        id_35  id_36  id_37  id_38  DeviceType  DeviceInfo  \n",
       "0           1      0      1      1           1         954  \n",
       "1           1      0      0      1           1        1727  \n",
       "2           0      0      1      1           0        1598  \n",
       "3           0      0      1      1           0          -1  \n",
       "4           1      0      1      1           0         723  \n",
       "...       ...    ...    ...    ...         ...         ...  \n",
       "590535     -1     -1     -1     -1          -1          -1  \n",
       "590536     -1     -1     -1     -1          -1          -1  \n",
       "590537     -1     -1     -1     -1          -1          -1  \n",
       "590538     -1     -1     -1     -1          -1          -1  \n",
       "590539     -1     -1     -1     -1          -1          -1  \n",
       "\n",
       "[590540 rows x 435 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['isFraud']\n",
    "for i in df:\n",
    "    df[i] = df[i].fillna(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID_left</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>4</td>\n",
       "      <td>13926</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>32.0</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590535</th>\n",
       "      <td>3577535</td>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>4</td>\n",
       "      <td>6550</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590536</th>\n",
       "      <td>3577536</td>\n",
       "      <td>0</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>4</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590537</th>\n",
       "      <td>3577537</td>\n",
       "      <td>0</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>4</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590538</th>\n",
       "      <td>3577538</td>\n",
       "      <td>0</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>4</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590539</th>\n",
       "      <td>3577539</td>\n",
       "      <td>0</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>4</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID_left  isFraud  TransactionDT  TransactionAmt  ProductCD  \\\n",
       "0                  2987000        0          86400           68.50          4   \n",
       "1                  2987001        0          86401           29.00          4   \n",
       "2                  2987002        0          86469           59.00          4   \n",
       "3                  2987003        0          86499           50.00          4   \n",
       "4                  2987004        0          86506           50.00          1   \n",
       "...                    ...      ...            ...             ...        ...   \n",
       "590535             3577535        0       15811047           49.00          4   \n",
       "590536             3577536        0       15811049           39.50          4   \n",
       "590537             3577537        0       15811079           30.95          4   \n",
       "590538             3577538        0       15811088          117.00          4   \n",
       "590539             3577539        0       15811131          279.95          4   \n",
       "\n",
       "        card1  card2  card3  card4  card5  ...  id_31  id_32  id_33  id_34  \\\n",
       "0       13926   -1.0  150.0      1  142.0  ...    123   32.0    164      3   \n",
       "1        2755  404.0  150.0      2  102.0  ...     98   32.0     48      2   \n",
       "2        4663  490.0  150.0      3  166.0  ...     44   -1.0     -1     -1   \n",
       "3       18132  567.0  150.0      2  117.0  ...     44   -1.0     -1     -1   \n",
       "4        4497  514.0  150.0      2  102.0  ...     44   24.0     40      3   \n",
       "...       ...    ...    ...    ...    ...  ...    ...    ...    ...    ...   \n",
       "590535   6550   -1.0  150.0      3  226.0  ...     -1   -1.0     -1     -1   \n",
       "590536  10444  225.0  150.0      2  224.0  ...     -1   -1.0     -1     -1   \n",
       "590537  12037  595.0  150.0      2  224.0  ...     -1   -1.0     -1     -1   \n",
       "590538   7826  481.0  150.0      2  224.0  ...     -1   -1.0     -1     -1   \n",
       "590539  15066  170.0  150.0      2  102.0  ...     -1   -1.0     -1     -1   \n",
       "\n",
       "        id_35  id_36  id_37  id_38  DeviceType  DeviceInfo  \n",
       "0           1      0      1      1           1         954  \n",
       "1           1      0      0      1           1        1727  \n",
       "2           0      0      1      1           0        1598  \n",
       "3           0      0      1      1           0          -1  \n",
       "4           1      0      1      1           0         723  \n",
       "...       ...    ...    ...    ...         ...         ...  \n",
       "590535     -1     -1     -1     -1          -1          -1  \n",
       "590536     -1     -1     -1     -1          -1          -1  \n",
       "590537     -1     -1     -1     -1          -1          -1  \n",
       "590538     -1     -1     -1     -1          -1          -1  \n",
       "590539     -1     -1     -1     -1          -1          -1  \n",
       "\n",
       "[590540 rows x 435 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(df-df.mean())/df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_df.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,y_test,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "y_val = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train', X_train)\n",
    "np.save('X_test', X_test)\n",
    "np.save('X_val', X_val)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_test', y_test)\n",
    "np.save('y_val', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prasoon Jha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Epoch 0, D-Loss: 0.7417185306549072, D-Accuracy: 0.53125, G-Loss: 0.7696181535720825\n",
      "Cluster 0, Epoch 1, D-Loss: 0.7261983156204224, D-Accuracy: 0.5625, G-Loss: 0.7725645303726196\n",
      "Cluster 0, Epoch 2, D-Loss: 0.6698751449584961, D-Accuracy: 0.578125, G-Loss: 0.6886141300201416\n",
      "Cluster 0, Epoch 3, D-Loss: 0.7503138780593872, D-Accuracy: 0.46875, G-Loss: 0.7042040824890137\n",
      "Cluster 0, Epoch 4, D-Loss: 0.6532741189002991, D-Accuracy: 0.53125, G-Loss: 0.669009804725647\n",
      "Cluster 0, Epoch 5, D-Loss: 0.7666728496551514, D-Accuracy: 0.625, G-Loss: 0.6641637682914734\n",
      "Cluster 0, Epoch 6, D-Loss: 0.7033135890960693, D-Accuracy: 0.4375, G-Loss: 0.6645755767822266\n",
      "Cluster 0, Epoch 7, D-Loss: 0.8102279901504517, D-Accuracy: 0.515625, G-Loss: 0.6697425246238708\n",
      "Cluster 0, Epoch 8, D-Loss: 0.6147289276123047, D-Accuracy: 0.578125, G-Loss: 0.6252045631408691\n",
      "Cluster 0, Epoch 9, D-Loss: 0.6047255396842957, D-Accuracy: 0.46875, G-Loss: 0.598521888256073\n",
      "Cluster 0, Epoch 10, D-Loss: 0.7680821418762207, D-Accuracy: 0.421875, G-Loss: 0.588214635848999\n",
      "Cluster 0, Epoch 11, D-Loss: 0.6350768804550171, D-Accuracy: 0.46875, G-Loss: 0.584052562713623\n",
      "Cluster 0, Epoch 12, D-Loss: 0.6762341856956482, D-Accuracy: 0.453125, G-Loss: 0.5969656109809875\n",
      "Cluster 0, Epoch 13, D-Loss: 0.6115429401397705, D-Accuracy: 0.5, G-Loss: 0.5945326089859009\n",
      "Cluster 0, Epoch 14, D-Loss: 0.6413397789001465, D-Accuracy: 0.5, G-Loss: 0.5838522911071777\n",
      "Cluster 0, Epoch 15, D-Loss: 0.6284705400466919, D-Accuracy: 0.59375, G-Loss: 0.582996129989624\n",
      "Cluster 0, Epoch 16, D-Loss: 0.6377195119857788, D-Accuracy: 0.578125, G-Loss: 0.5768535137176514\n",
      "Cluster 0, Epoch 17, D-Loss: 0.6721633672714233, D-Accuracy: 0.53125, G-Loss: 0.5573710203170776\n",
      "Cluster 0, Epoch 18, D-Loss: 0.6212306022644043, D-Accuracy: 0.5, G-Loss: 0.5582436323165894\n",
      "Cluster 0, Epoch 19, D-Loss: 0.8056768178939819, D-Accuracy: 0.53125, G-Loss: 0.5028905272483826\n",
      "Cluster 0, Epoch 20, D-Loss: 0.5860445499420166, D-Accuracy: 0.53125, G-Loss: 0.5642514228820801\n",
      "Cluster 0, Epoch 21, D-Loss: 0.658362090587616, D-Accuracy: 0.484375, G-Loss: 0.5227829217910767\n",
      "Cluster 0, Epoch 22, D-Loss: 0.8472071886062622, D-Accuracy: 0.53125, G-Loss: 0.5444814562797546\n",
      "Cluster 0, Epoch 23, D-Loss: 0.6132556200027466, D-Accuracy: 0.53125, G-Loss: 0.4932102859020233\n",
      "Cluster 0, Epoch 24, D-Loss: 0.5891505479812622, D-Accuracy: 0.5, G-Loss: 0.5249992609024048\n",
      "Cluster 0, Epoch 25, D-Loss: 0.6301898956298828, D-Accuracy: 0.484375, G-Loss: 0.5015648603439331\n",
      "Cluster 0, Epoch 26, D-Loss: 0.6443236470222473, D-Accuracy: 0.484375, G-Loss: 0.5352224111557007\n",
      "Cluster 0, Epoch 27, D-Loss: 0.6667724847793579, D-Accuracy: 0.46875, G-Loss: 0.542775571346283\n",
      "Cluster 0, Epoch 28, D-Loss: 0.7434189319610596, D-Accuracy: 0.5, G-Loss: 0.5159748792648315\n",
      "Cluster 0, Epoch 29, D-Loss: 0.5720731019973755, D-Accuracy: 0.53125, G-Loss: 0.5220224857330322\n",
      "Cluster 0, Epoch 30, D-Loss: 0.6535581946372986, D-Accuracy: 0.484375, G-Loss: 0.5016494989395142\n",
      "Cluster 0, Epoch 31, D-Loss: 0.7745373249053955, D-Accuracy: 0.5, G-Loss: 0.525381863117218\n",
      "Cluster 0, Epoch 32, D-Loss: 0.6035721302032471, D-Accuracy: 0.5, G-Loss: 0.5185173153877258\n",
      "Cluster 0, Epoch 33, D-Loss: 0.6165761947631836, D-Accuracy: 0.5, G-Loss: 0.5456670522689819\n",
      "Cluster 0, Epoch 34, D-Loss: 0.6301901936531067, D-Accuracy: 0.46875, G-Loss: 0.48695313930511475\n",
      "Cluster 0, Epoch 35, D-Loss: 0.6192494034767151, D-Accuracy: 0.53125, G-Loss: 0.48804691433906555\n",
      "Cluster 0, Epoch 36, D-Loss: 0.6105421781539917, D-Accuracy: 0.484375, G-Loss: 0.5321583151817322\n",
      "Cluster 0, Epoch 37, D-Loss: 0.6732103824615479, D-Accuracy: 0.484375, G-Loss: 0.5443364381790161\n",
      "Cluster 0, Epoch 38, D-Loss: 0.579991340637207, D-Accuracy: 0.515625, G-Loss: 0.5008960366249084\n",
      "Cluster 0, Epoch 39, D-Loss: 0.6276413202285767, D-Accuracy: 0.5, G-Loss: 0.551402747631073\n",
      "Cluster 0, Epoch 40, D-Loss: 0.541400134563446, D-Accuracy: 0.5, G-Loss: 0.5591578483581543\n",
      "Cluster 0, Epoch 41, D-Loss: 0.5684785842895508, D-Accuracy: 0.53125, G-Loss: 0.5391660332679749\n",
      "Cluster 0, Epoch 42, D-Loss: 0.6471701860427856, D-Accuracy: 0.5, G-Loss: 0.5158776640892029\n",
      "Cluster 0, Epoch 43, D-Loss: 0.5785823464393616, D-Accuracy: 0.546875, G-Loss: 0.5512802600860596\n",
      "Cluster 0, Epoch 44, D-Loss: 0.5938072204589844, D-Accuracy: 0.515625, G-Loss: 0.5381507277488708\n",
      "Cluster 0, Epoch 45, D-Loss: 0.6221514940261841, D-Accuracy: 0.453125, G-Loss: 0.5524070858955383\n",
      "Cluster 0, Epoch 46, D-Loss: 0.6019548177719116, D-Accuracy: 0.5, G-Loss: 0.5187453031539917\n",
      "Cluster 0, Epoch 47, D-Loss: 0.5863839387893677, D-Accuracy: 0.5, G-Loss: 0.5523204803466797\n",
      "Cluster 0, Epoch 48, D-Loss: 0.605454683303833, D-Accuracy: 0.484375, G-Loss: 0.5870990753173828\n",
      "Cluster 0, Epoch 49, D-Loss: 0.5490323305130005, D-Accuracy: 0.5625, G-Loss: 0.5582438111305237\n",
      "Cluster 1, Epoch 0, D-Loss: 1.7116098403930664, D-Accuracy: 0.625, G-Loss: 0.9698240160942078\n",
      "Cluster 1, Epoch 1, D-Loss: 1.9249553680419922, D-Accuracy: 0.734375, G-Loss: 0.930299699306488\n",
      "Cluster 1, Epoch 2, D-Loss: 1.6995773315429688, D-Accuracy: 0.640625, G-Loss: 0.9046872854232788\n",
      "Cluster 1, Epoch 3, D-Loss: 1.159622311592102, D-Accuracy: 0.78125, G-Loss: 0.8810432553291321\n",
      "Cluster 1, Epoch 4, D-Loss: 1.2361421585083008, D-Accuracy: 0.6875, G-Loss: 0.8648073673248291\n",
      "Cluster 1, Epoch 5, D-Loss: 0.6757347583770752, D-Accuracy: 0.78125, G-Loss: 0.8433189392089844\n",
      "Cluster 1, Epoch 6, D-Loss: 0.6044392585754395, D-Accuracy: 0.84375, G-Loss: 0.8020128011703491\n",
      "Cluster 1, Epoch 7, D-Loss: 0.862697184085846, D-Accuracy: 0.71875, G-Loss: 0.8743347525596619\n",
      "Cluster 1, Epoch 8, D-Loss: 0.4817981719970703, D-Accuracy: 0.78125, G-Loss: 0.811827540397644\n",
      "Cluster 1, Epoch 9, D-Loss: 0.561829149723053, D-Accuracy: 0.828125, G-Loss: 0.7937344908714294\n",
      "Cluster 1, Epoch 10, D-Loss: 0.44837072491645813, D-Accuracy: 0.8125, G-Loss: 0.7503268122673035\n",
      "Cluster 1, Epoch 11, D-Loss: 0.454954594373703, D-Accuracy: 0.734375, G-Loss: 0.7753764390945435\n",
      "Cluster 1, Epoch 12, D-Loss: 0.3554273247718811, D-Accuracy: 0.796875, G-Loss: 0.7736079692840576\n",
      "Cluster 1, Epoch 13, D-Loss: 0.49261265993118286, D-Accuracy: 0.734375, G-Loss: 0.7447354197502136\n",
      "Cluster 1, Epoch 14, D-Loss: 0.4018641710281372, D-Accuracy: 0.703125, G-Loss: 0.7227434515953064\n",
      "Cluster 1, Epoch 15, D-Loss: 0.4539138376712799, D-Accuracy: 0.703125, G-Loss: 0.7053897380828857\n",
      "Cluster 1, Epoch 16, D-Loss: 0.5802462697029114, D-Accuracy: 0.703125, G-Loss: 0.7072393298149109\n",
      "Cluster 1, Epoch 17, D-Loss: 0.5799276232719421, D-Accuracy: 0.609375, G-Loss: 0.6935455203056335\n",
      "Cluster 1, Epoch 18, D-Loss: 0.4138728976249695, D-Accuracy: 0.65625, G-Loss: 0.6398880481719971\n",
      "Cluster 1, Epoch 19, D-Loss: 0.4070442020893097, D-Accuracy: 0.625, G-Loss: 0.6671266555786133\n",
      "Cluster 1, Epoch 20, D-Loss: 0.3903837203979492, D-Accuracy: 0.671875, G-Loss: 0.6624113321304321\n",
      "Cluster 1, Epoch 21, D-Loss: 0.411284863948822, D-Accuracy: 0.65625, G-Loss: 0.6469399929046631\n",
      "Cluster 1, Epoch 22, D-Loss: 0.40546274185180664, D-Accuracy: 0.609375, G-Loss: 0.6286494731903076\n",
      "Cluster 1, Epoch 23, D-Loss: 0.4190421998500824, D-Accuracy: 0.71875, G-Loss: 0.6419529318809509\n",
      "Cluster 1, Epoch 24, D-Loss: 0.4388335347175598, D-Accuracy: 0.609375, G-Loss: 0.6202046871185303\n",
      "Cluster 1, Epoch 25, D-Loss: 0.42997539043426514, D-Accuracy: 0.5625, G-Loss: 0.6228477954864502\n",
      "Cluster 1, Epoch 26, D-Loss: 0.519737958908081, D-Accuracy: 0.609375, G-Loss: 0.636593222618103\n",
      "Cluster 1, Epoch 27, D-Loss: 0.42674267292022705, D-Accuracy: 0.609375, G-Loss: 0.6372452974319458\n",
      "Cluster 1, Epoch 28, D-Loss: 0.441679447889328, D-Accuracy: 0.5625, G-Loss: 0.6258696913719177\n",
      "Cluster 1, Epoch 29, D-Loss: 0.4682484269142151, D-Accuracy: 0.546875, G-Loss: 0.6195388436317444\n",
      "Cluster 1, Epoch 30, D-Loss: 0.43136054277420044, D-Accuracy: 0.59375, G-Loss: 0.5996367931365967\n",
      "Cluster 1, Epoch 31, D-Loss: 0.45493602752685547, D-Accuracy: 0.5625, G-Loss: 0.632598340511322\n",
      "Cluster 1, Epoch 32, D-Loss: 0.4591105878353119, D-Accuracy: 0.5625, G-Loss: 0.6132897138595581\n",
      "Cluster 1, Epoch 33, D-Loss: 0.5022050142288208, D-Accuracy: 0.515625, G-Loss: 0.5852229595184326\n",
      "Cluster 1, Epoch 34, D-Loss: 0.44280126690864563, D-Accuracy: 0.53125, G-Loss: 0.6038103699684143\n",
      "Cluster 1, Epoch 35, D-Loss: 0.453409343957901, D-Accuracy: 0.59375, G-Loss: 0.585514485836029\n",
      "Cluster 1, Epoch 36, D-Loss: 0.4951780438423157, D-Accuracy: 0.5, G-Loss: 0.603728711605072\n",
      "Cluster 1, Epoch 37, D-Loss: 0.4920576512813568, D-Accuracy: 0.546875, G-Loss: 0.5998983383178711\n",
      "Cluster 1, Epoch 38, D-Loss: 0.44022923707962036, D-Accuracy: 0.59375, G-Loss: 0.5961507558822632\n",
      "Cluster 1, Epoch 39, D-Loss: 0.4125022292137146, D-Accuracy: 0.578125, G-Loss: 0.5748931169509888\n",
      "Cluster 1, Epoch 40, D-Loss: 0.44478297233581543, D-Accuracy: 0.53125, G-Loss: 0.5805975198745728\n",
      "Cluster 1, Epoch 41, D-Loss: 0.4377965033054352, D-Accuracy: 0.546875, G-Loss: 0.5691705346107483\n",
      "Cluster 1, Epoch 42, D-Loss: 0.48649486899375916, D-Accuracy: 0.53125, G-Loss: 0.597095787525177\n",
      "Cluster 1, Epoch 43, D-Loss: 0.4416995644569397, D-Accuracy: 0.578125, G-Loss: 0.5921924114227295\n",
      "Cluster 1, Epoch 44, D-Loss: 0.47005122900009155, D-Accuracy: 0.53125, G-Loss: 0.555840015411377\n",
      "Cluster 1, Epoch 45, D-Loss: 0.4657391309738159, D-Accuracy: 0.5625, G-Loss: 0.5994853377342224\n",
      "Cluster 1, Epoch 46, D-Loss: 0.4617615342140198, D-Accuracy: 0.5625, G-Loss: 0.5982116460800171\n",
      "Cluster 1, Epoch 47, D-Loss: 0.4482848048210144, D-Accuracy: 0.59375, G-Loss: 0.5927966833114624\n",
      "Cluster 1, Epoch 48, D-Loss: 0.4196142256259918, D-Accuracy: 0.53125, G-Loss: 0.5648782253265381\n",
      "Cluster 1, Epoch 49, D-Loss: 0.4591436982154846, D-Accuracy: 0.515625, G-Loss: 0.5841882228851318\n",
      "Cluster 2, Epoch 0, D-Loss: 0.4900173246860504, D-Accuracy: 0.71875, G-Loss: 0.6922671794891357\n",
      "Cluster 2, Epoch 1, D-Loss: 0.5402517318725586, D-Accuracy: 0.59375, G-Loss: 0.6303113698959351\n",
      "Cluster 2, Epoch 2, D-Loss: 0.46575701236724854, D-Accuracy: 0.65625, G-Loss: 0.6057560443878174\n",
      "Cluster 2, Epoch 3, D-Loss: 0.46993255615234375, D-Accuracy: 0.59375, G-Loss: 0.6297311186790466\n",
      "Cluster 2, Epoch 4, D-Loss: 0.45735716819763184, D-Accuracy: 0.640625, G-Loss: 0.6282261610031128\n",
      "Cluster 2, Epoch 5, D-Loss: 0.4472832679748535, D-Accuracy: 0.609375, G-Loss: 0.6376487016677856\n",
      "Cluster 2, Epoch 6, D-Loss: 0.4209575653076172, D-Accuracy: 0.5625, G-Loss: 0.5962008833885193\n",
      "Cluster 2, Epoch 7, D-Loss: 0.43769973516464233, D-Accuracy: 0.59375, G-Loss: 0.6008404493331909\n",
      "Cluster 2, Epoch 8, D-Loss: 0.4735172688961029, D-Accuracy: 0.53125, G-Loss: 0.6299405097961426\n",
      "Cluster 2, Epoch 9, D-Loss: 0.43000221252441406, D-Accuracy: 0.609375, G-Loss: 0.6032534837722778\n",
      "Cluster 2, Epoch 10, D-Loss: 0.4602593779563904, D-Accuracy: 0.5625, G-Loss: 0.5680965185165405\n",
      "Cluster 2, Epoch 11, D-Loss: 0.4356713891029358, D-Accuracy: 0.59375, G-Loss: 0.5798461437225342\n",
      "Cluster 2, Epoch 12, D-Loss: 0.4334257245063782, D-Accuracy: 0.609375, G-Loss: 0.6137359142303467\n",
      "Cluster 2, Epoch 13, D-Loss: 0.4275957942008972, D-Accuracy: 0.578125, G-Loss: 0.5645233392715454\n",
      "Cluster 2, Epoch 14, D-Loss: 0.4476010203361511, D-Accuracy: 0.5625, G-Loss: 0.5913864374160767\n",
      "Cluster 2, Epoch 15, D-Loss: 0.4591738283634186, D-Accuracy: 0.578125, G-Loss: 0.5904147624969482\n",
      "Cluster 2, Epoch 16, D-Loss: 0.45161116123199463, D-Accuracy: 0.578125, G-Loss: 0.554351806640625\n",
      "Cluster 2, Epoch 17, D-Loss: 0.4305463433265686, D-Accuracy: 0.5625, G-Loss: 0.5809675455093384\n",
      "Cluster 2, Epoch 18, D-Loss: 0.4498617649078369, D-Accuracy: 0.53125, G-Loss: 0.5775202512741089\n",
      "Cluster 2, Epoch 19, D-Loss: 0.422685444355011, D-Accuracy: 0.609375, G-Loss: 0.6154608726501465\n",
      "Cluster 2, Epoch 20, D-Loss: 0.4395138919353485, D-Accuracy: 0.5625, G-Loss: 0.5977540016174316\n",
      "Cluster 2, Epoch 21, D-Loss: 0.45677098631858826, D-Accuracy: 0.59375, G-Loss: 0.5601771473884583\n",
      "Cluster 2, Epoch 22, D-Loss: 0.47823387384414673, D-Accuracy: 0.53125, G-Loss: 0.6143801212310791\n",
      "Cluster 2, Epoch 23, D-Loss: 0.4563067555427551, D-Accuracy: 0.578125, G-Loss: 0.590782880783081\n",
      "Cluster 2, Epoch 24, D-Loss: 0.4153765141963959, D-Accuracy: 0.640625, G-Loss: 0.5609018802642822\n",
      "Cluster 2, Epoch 25, D-Loss: 0.4504420757293701, D-Accuracy: 0.59375, G-Loss: 0.5913243889808655\n",
      "Cluster 2, Epoch 26, D-Loss: 0.44495058059692383, D-Accuracy: 0.59375, G-Loss: 0.5823805928230286\n",
      "Cluster 2, Epoch 27, D-Loss: 0.4677175283432007, D-Accuracy: 0.59375, G-Loss: 0.6220457553863525\n",
      "Cluster 2, Epoch 28, D-Loss: 0.471673846244812, D-Accuracy: 0.5625, G-Loss: 0.6043052673339844\n",
      "Cluster 2, Epoch 29, D-Loss: 0.4265475273132324, D-Accuracy: 0.578125, G-Loss: 0.6582204699516296\n",
      "Cluster 2, Epoch 30, D-Loss: 0.4054523706436157, D-Accuracy: 0.640625, G-Loss: 0.6582105755805969\n",
      "Cluster 2, Epoch 31, D-Loss: 0.41681671142578125, D-Accuracy: 0.625, G-Loss: 0.6164834499359131\n",
      "Cluster 2, Epoch 32, D-Loss: 0.42276933789253235, D-Accuracy: 0.609375, G-Loss: 0.6818839311599731\n",
      "Cluster 2, Epoch 33, D-Loss: 0.43656060099601746, D-Accuracy: 0.59375, G-Loss: 0.6644361019134521\n",
      "Cluster 2, Epoch 34, D-Loss: 0.4043063819408417, D-Accuracy: 0.609375, G-Loss: 0.6185311079025269\n",
      "Cluster 2, Epoch 35, D-Loss: 0.39703369140625, D-Accuracy: 0.6875, G-Loss: 0.669511079788208\n",
      "Cluster 2, Epoch 36, D-Loss: 0.40908682346343994, D-Accuracy: 0.625, G-Loss: 0.6639878749847412\n",
      "Cluster 2, Epoch 37, D-Loss: 0.4073164463043213, D-Accuracy: 0.625, G-Loss: 0.6800208687782288\n",
      "Cluster 2, Epoch 38, D-Loss: 0.3913656175136566, D-Accuracy: 0.625, G-Loss: 0.6513000726699829\n",
      "Cluster 2, Epoch 39, D-Loss: 0.3936530649662018, D-Accuracy: 0.640625, G-Loss: 0.7187033891677856\n",
      "Cluster 2, Epoch 40, D-Loss: 0.41308242082595825, D-Accuracy: 0.65625, G-Loss: 0.6422691941261292\n",
      "Cluster 2, Epoch 41, D-Loss: 0.3896735608577728, D-Accuracy: 0.625, G-Loss: 0.698523998260498\n",
      "Cluster 2, Epoch 42, D-Loss: 0.397228479385376, D-Accuracy: 0.71875, G-Loss: 0.6834515333175659\n",
      "Cluster 2, Epoch 43, D-Loss: 0.37730517983436584, D-Accuracy: 0.71875, G-Loss: 0.700472891330719\n",
      "Cluster 2, Epoch 44, D-Loss: 0.3805145025253296, D-Accuracy: 0.71875, G-Loss: 0.7470879554748535\n",
      "Cluster 2, Epoch 45, D-Loss: 0.36876624822616577, D-Accuracy: 0.75, G-Loss: 0.7083966135978699\n",
      "Cluster 2, Epoch 46, D-Loss: 0.39895129203796387, D-Accuracy: 0.75, G-Loss: 0.7116831541061401\n",
      "Cluster 2, Epoch 47, D-Loss: 0.3848915994167328, D-Accuracy: 0.703125, G-Loss: 0.7171415090560913\n",
      "Cluster 2, Epoch 48, D-Loss: 0.3718957304954529, D-Accuracy: 0.734375, G-Loss: 0.7133678197860718\n",
      "Cluster 2, Epoch 49, D-Loss: 0.35924673080444336, D-Accuracy: 0.703125, G-Loss: 0.7589070796966553\n",
      "Cluster 3, Epoch 0, D-Loss: 0.689603865146637, D-Accuracy: 0.46875, G-Loss: 0.582487940788269\n",
      "Cluster 3, Epoch 1, D-Loss: 0.4936009645462036, D-Accuracy: 0.5625, G-Loss: 0.5825471878051758\n",
      "Cluster 3, Epoch 2, D-Loss: 0.5057980418205261, D-Accuracy: 0.53125, G-Loss: 0.5856948494911194\n",
      "Cluster 3, Epoch 3, D-Loss: 0.4797492027282715, D-Accuracy: 0.609375, G-Loss: 0.6169156432151794\n",
      "Cluster 3, Epoch 4, D-Loss: 0.5000481605529785, D-Accuracy: 0.515625, G-Loss: 0.5660154223442078\n",
      "Cluster 3, Epoch 5, D-Loss: 0.4393358826637268, D-Accuracy: 0.578125, G-Loss: 0.567481517791748\n",
      "Cluster 3, Epoch 6, D-Loss: 0.4452730715274811, D-Accuracy: 0.578125, G-Loss: 0.5479412078857422\n",
      "Cluster 3, Epoch 7, D-Loss: 0.4886862635612488, D-Accuracy: 0.515625, G-Loss: 0.5637328028678894\n",
      "Cluster 3, Epoch 8, D-Loss: 0.4885428547859192, D-Accuracy: 0.53125, G-Loss: 0.5789320468902588\n",
      "Cluster 3, Epoch 9, D-Loss: 0.5235282182693481, D-Accuracy: 0.546875, G-Loss: 0.5746105313301086\n",
      "Cluster 3, Epoch 10, D-Loss: 0.462441086769104, D-Accuracy: 0.578125, G-Loss: 0.5446380972862244\n",
      "Cluster 3, Epoch 11, D-Loss: 0.45058321952819824, D-Accuracy: 0.578125, G-Loss: 0.5781183838844299\n",
      "Cluster 3, Epoch 12, D-Loss: 0.45696210861206055, D-Accuracy: 0.5625, G-Loss: 0.5435328483581543\n",
      "Cluster 3, Epoch 13, D-Loss: 0.5535696744918823, D-Accuracy: 0.5625, G-Loss: 0.5278192162513733\n",
      "Cluster 3, Epoch 14, D-Loss: 0.48932504653930664, D-Accuracy: 0.53125, G-Loss: 0.597636878490448\n",
      "Cluster 3, Epoch 15, D-Loss: 0.4504735469818115, D-Accuracy: 0.53125, G-Loss: 0.5694103240966797\n",
      "Cluster 3, Epoch 16, D-Loss: 0.4654977023601532, D-Accuracy: 0.5, G-Loss: 0.5707327127456665\n",
      "Cluster 3, Epoch 17, D-Loss: 0.4320715665817261, D-Accuracy: 0.5625, G-Loss: 0.5586415529251099\n",
      "Cluster 3, Epoch 18, D-Loss: 0.48010197281837463, D-Accuracy: 0.5625, G-Loss: 0.5699851512908936\n",
      "Cluster 3, Epoch 19, D-Loss: 0.4613645076751709, D-Accuracy: 0.53125, G-Loss: 0.5423547029495239\n",
      "Cluster 3, Epoch 20, D-Loss: 0.46910837292671204, D-Accuracy: 0.5625, G-Loss: 0.5742835998535156\n",
      "Cluster 3, Epoch 21, D-Loss: 0.4638214707374573, D-Accuracy: 0.5625, G-Loss: 0.5716526508331299\n",
      "Cluster 3, Epoch 22, D-Loss: 0.4530627429485321, D-Accuracy: 0.578125, G-Loss: 0.5494844913482666\n",
      "Cluster 3, Epoch 23, D-Loss: 0.4494805932044983, D-Accuracy: 0.53125, G-Loss: 0.5767529010772705\n",
      "Cluster 3, Epoch 24, D-Loss: 0.48439961671829224, D-Accuracy: 0.546875, G-Loss: 0.5419082641601562\n",
      "Cluster 3, Epoch 25, D-Loss: 0.4821484088897705, D-Accuracy: 0.515625, G-Loss: 0.5202712416648865\n",
      "Cluster 3, Epoch 26, D-Loss: 0.47133147716522217, D-Accuracy: 0.5, G-Loss: 0.5436071753501892\n",
      "Cluster 3, Epoch 27, D-Loss: 0.49623697996139526, D-Accuracy: 0.484375, G-Loss: 0.5894615650177002\n",
      "Cluster 3, Epoch 28, D-Loss: 0.4546794295310974, D-Accuracy: 0.59375, G-Loss: 0.5979852676391602\n",
      "Cluster 3, Epoch 29, D-Loss: 0.4557247757911682, D-Accuracy: 0.546875, G-Loss: 0.607151985168457\n",
      "Cluster 3, Epoch 30, D-Loss: 0.46148625016212463, D-Accuracy: 0.546875, G-Loss: 0.5628948211669922\n",
      "Cluster 3, Epoch 31, D-Loss: 0.4455731511116028, D-Accuracy: 0.546875, G-Loss: 0.5930805206298828\n",
      "Cluster 3, Epoch 32, D-Loss: 0.44245123863220215, D-Accuracy: 0.578125, G-Loss: 0.5755597949028015\n",
      "Cluster 3, Epoch 33, D-Loss: 0.47840699553489685, D-Accuracy: 0.515625, G-Loss: 0.5830950736999512\n",
      "Cluster 3, Epoch 34, D-Loss: 0.4701997637748718, D-Accuracy: 0.5625, G-Loss: 0.5947389602661133\n",
      "Cluster 3, Epoch 35, D-Loss: 0.4385782480239868, D-Accuracy: 0.546875, G-Loss: 0.5906388163566589\n",
      "Cluster 3, Epoch 36, D-Loss: 0.4424383044242859, D-Accuracy: 0.5625, G-Loss: 0.5728437304496765\n",
      "Cluster 3, Epoch 37, D-Loss: 0.4333285987377167, D-Accuracy: 0.578125, G-Loss: 0.6178712248802185\n",
      "Cluster 3, Epoch 38, D-Loss: 0.42029425501823425, D-Accuracy: 0.625, G-Loss: 0.6208528280258179\n",
      "Cluster 3, Epoch 39, D-Loss: 0.4194996953010559, D-Accuracy: 0.5625, G-Loss: 0.6337848901748657\n",
      "Cluster 3, Epoch 40, D-Loss: 0.42571204900741577, D-Accuracy: 0.609375, G-Loss: 0.5891022682189941\n",
      "Cluster 3, Epoch 41, D-Loss: 0.4409157633781433, D-Accuracy: 0.546875, G-Loss: 0.6224170327186584\n",
      "Cluster 3, Epoch 42, D-Loss: 0.4402620494365692, D-Accuracy: 0.578125, G-Loss: 0.5998259782791138\n",
      "Cluster 3, Epoch 43, D-Loss: 0.41841816902160645, D-Accuracy: 0.59375, G-Loss: 0.6518803834915161\n",
      "Cluster 3, Epoch 44, D-Loss: 0.40286147594451904, D-Accuracy: 0.578125, G-Loss: 0.6476901173591614\n",
      "Cluster 3, Epoch 45, D-Loss: 0.41012704372406006, D-Accuracy: 0.609375, G-Loss: 0.6378582119941711\n",
      "Cluster 3, Epoch 46, D-Loss: 0.40606236457824707, D-Accuracy: 0.65625, G-Loss: 0.6321173906326294\n",
      "Cluster 3, Epoch 47, D-Loss: 0.3991715908050537, D-Accuracy: 0.640625, G-Loss: 0.6587303876876831\n",
      "Cluster 3, Epoch 48, D-Loss: 0.381658673286438, D-Accuracy: 0.71875, G-Loss: 0.6294306516647339\n",
      "Cluster 3, Epoch 49, D-Loss: 0.4037436842918396, D-Accuracy: 0.59375, G-Loss: 0.6489684581756592\n",
      "Cluster 4, Epoch 0, D-Loss: 1.0320416688919067, D-Accuracy: 0.578125, G-Loss: 0.8466525077819824\n",
      "Cluster 4, Epoch 1, D-Loss: 0.8399721384048462, D-Accuracy: 0.5625, G-Loss: 0.8280768394470215\n",
      "Cluster 4, Epoch 2, D-Loss: 0.6805216073989868, D-Accuracy: 0.65625, G-Loss: 0.7827930450439453\n",
      "Cluster 4, Epoch 3, D-Loss: 0.6413849592208862, D-Accuracy: 0.671875, G-Loss: 0.7879942059516907\n",
      "Cluster 4, Epoch 4, D-Loss: 0.5567307472229004, D-Accuracy: 0.703125, G-Loss: 0.7636114954948425\n",
      "Cluster 4, Epoch 5, D-Loss: 0.5172640681266785, D-Accuracy: 0.78125, G-Loss: 0.7609405517578125\n",
      "Cluster 4, Epoch 6, D-Loss: 0.5399144291877747, D-Accuracy: 0.671875, G-Loss: 0.762049674987793\n",
      "Cluster 4, Epoch 7, D-Loss: 0.5557572841644287, D-Accuracy: 0.65625, G-Loss: 0.7377456426620483\n",
      "Cluster 4, Epoch 8, D-Loss: 0.5115395188331604, D-Accuracy: 0.65625, G-Loss: 0.7203991413116455\n",
      "Cluster 4, Epoch 9, D-Loss: 0.4764082431793213, D-Accuracy: 0.65625, G-Loss: 0.692103385925293\n",
      "Cluster 4, Epoch 10, D-Loss: 0.4782685339450836, D-Accuracy: 0.609375, G-Loss: 0.6836638450622559\n",
      "Cluster 4, Epoch 11, D-Loss: 0.42228811979293823, D-Accuracy: 0.75, G-Loss: 0.6960253715515137\n",
      "Cluster 4, Epoch 12, D-Loss: 0.5230379104614258, D-Accuracy: 0.6875, G-Loss: 0.6837247610092163\n",
      "Cluster 4, Epoch 13, D-Loss: 0.4312369227409363, D-Accuracy: 0.703125, G-Loss: 0.6769087314605713\n",
      "Cluster 4, Epoch 14, D-Loss: 0.46482977271080017, D-Accuracy: 0.671875, G-Loss: 0.6547242999076843\n",
      "Cluster 4, Epoch 15, D-Loss: 0.5012556314468384, D-Accuracy: 0.59375, G-Loss: 0.6237563490867615\n",
      "Cluster 4, Epoch 16, D-Loss: 0.4250847399234772, D-Accuracy: 0.671875, G-Loss: 0.6423366069793701\n",
      "Cluster 4, Epoch 17, D-Loss: 0.43405091762542725, D-Accuracy: 0.578125, G-Loss: 0.6260600090026855\n",
      "Cluster 4, Epoch 18, D-Loss: 0.44471973180770874, D-Accuracy: 0.578125, G-Loss: 0.6249338984489441\n",
      "Cluster 4, Epoch 19, D-Loss: 0.4600350856781006, D-Accuracy: 0.578125, G-Loss: 0.5741636753082275\n",
      "Cluster 4, Epoch 20, D-Loss: 0.43896782398223877, D-Accuracy: 0.5625, G-Loss: 0.6390069127082825\n",
      "Cluster 4, Epoch 21, D-Loss: 0.46384796500205994, D-Accuracy: 0.546875, G-Loss: 0.5951912999153137\n",
      "Cluster 4, Epoch 22, D-Loss: 0.48716169595718384, D-Accuracy: 0.53125, G-Loss: 0.6225705742835999\n",
      "Cluster 4, Epoch 23, D-Loss: 0.447033166885376, D-Accuracy: 0.578125, G-Loss: 0.5872708559036255\n",
      "Cluster 4, Epoch 24, D-Loss: 0.4449945092201233, D-Accuracy: 0.546875, G-Loss: 0.606766939163208\n",
      "Cluster 4, Epoch 25, D-Loss: 0.47821229696273804, D-Accuracy: 0.5, G-Loss: 0.585716962814331\n",
      "Cluster 4, Epoch 26, D-Loss: 0.46768906712532043, D-Accuracy: 0.515625, G-Loss: 0.5964093208312988\n",
      "Cluster 4, Epoch 27, D-Loss: 0.4619770050048828, D-Accuracy: 0.515625, G-Loss: 0.5847012996673584\n",
      "Cluster 4, Epoch 28, D-Loss: 0.4738028943538666, D-Accuracy: 0.5625, G-Loss: 0.553007960319519\n",
      "Cluster 4, Epoch 29, D-Loss: 0.43279215693473816, D-Accuracy: 0.546875, G-Loss: 0.5379468202590942\n",
      "Cluster 4, Epoch 30, D-Loss: 0.4871395230293274, D-Accuracy: 0.53125, G-Loss: 0.5486162900924683\n",
      "Cluster 4, Epoch 31, D-Loss: 0.5064637660980225, D-Accuracy: 0.515625, G-Loss: 0.5453196167945862\n",
      "Cluster 4, Epoch 32, D-Loss: 0.515592634677887, D-Accuracy: 0.515625, G-Loss: 0.5627453327178955\n",
      "Cluster 4, Epoch 33, D-Loss: 0.49347585439682007, D-Accuracy: 0.53125, G-Loss: 0.5620191097259521\n",
      "Cluster 4, Epoch 34, D-Loss: 0.5089815258979797, D-Accuracy: 0.53125, G-Loss: 0.5481205582618713\n",
      "Cluster 4, Epoch 35, D-Loss: 0.48189735412597656, D-Accuracy: 0.515625, G-Loss: 0.5762980580329895\n",
      "Cluster 4, Epoch 36, D-Loss: 0.522006094455719, D-Accuracy: 0.515625, G-Loss: 0.5341291427612305\n",
      "Cluster 4, Epoch 37, D-Loss: 0.45630764961242676, D-Accuracy: 0.5, G-Loss: 0.5202007293701172\n",
      "Cluster 4, Epoch 38, D-Loss: 0.5097694396972656, D-Accuracy: 0.546875, G-Loss: 0.529340386390686\n",
      "Cluster 4, Epoch 39, D-Loss: 0.5411841869354248, D-Accuracy: 0.5, G-Loss: 0.5397545695304871\n",
      "Cluster 4, Epoch 40, D-Loss: 0.48648226261138916, D-Accuracy: 0.546875, G-Loss: 0.5239239931106567\n",
      "Cluster 4, Epoch 41, D-Loss: 0.4967139959335327, D-Accuracy: 0.53125, G-Loss: 0.5434909462928772\n",
      "Cluster 4, Epoch 42, D-Loss: 0.5284504890441895, D-Accuracy: 0.484375, G-Loss: 0.5044490098953247\n",
      "Cluster 4, Epoch 43, D-Loss: 0.49180710315704346, D-Accuracy: 0.5625, G-Loss: 0.5043062567710876\n",
      "Cluster 4, Epoch 44, D-Loss: 0.5045817494392395, D-Accuracy: 0.578125, G-Loss: 0.5570013523101807\n",
      "Cluster 4, Epoch 45, D-Loss: 0.5320972204208374, D-Accuracy: 0.515625, G-Loss: 0.5084942579269409\n",
      "Cluster 4, Epoch 46, D-Loss: 0.521928071975708, D-Accuracy: 0.515625, G-Loss: 0.5034440755844116\n",
      "Cluster 4, Epoch 47, D-Loss: 0.5186358094215393, D-Accuracy: 0.515625, G-Loss: 0.5201471447944641\n",
      "Cluster 4, Epoch 48, D-Loss: 0.45213302969932556, D-Accuracy: 0.5, G-Loss: 0.5471212267875671\n",
      "Cluster 4, Epoch 49, D-Loss: 0.4987265467643738, D-Accuracy: 0.53125, G-Loss: 0.5424799919128418\n",
      "Epoch 1/10\n",
      "14780/14780 [==============================] - 38s 2ms/step - loss: 0.1149 - accuracy: 0.9699\n",
      "Epoch 2/10\n",
      "14780/14780 [==============================] - 44s 3ms/step - loss: 0.1053 - accuracy: 0.9722\n",
      "Epoch 3/10\n",
      "14780/14780 [==============================] - 55s 4ms/step - loss: 0.1013 - accuracy: 0.9731\n",
      "Epoch 4/10\n",
      "14780/14780 [==============================] - 42s 3ms/step - loss: 0.0990 - accuracy: 0.9738\n",
      "Epoch 5/10\n",
      "14780/14780 [==============================] - 33s 2ms/step - loss: 0.0971 - accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "14780/14780 [==============================] - 31s 2ms/step - loss: 0.0955 - accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "14780/14780 [==============================] - 32s 2ms/step - loss: 0.0942 - accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "14780/14780 [==============================] - 40s 3ms/step - loss: 0.0934 - accuracy: 0.9755 0s - loss: 0.0934 - accuracy: 0.\n",
      "Epoch 9/10\n",
      "14780/14780 [==============================] - 41s 3ms/step - loss: 0.0923 - accuracy: 0.9757\n",
      "Epoch 10/10\n",
      "14780/14780 [==============================] - 43s 3ms/step - loss: 0.0916 - accuracy: 0.9759\n",
      "[[90986    72]\n",
      " [ 2424  1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     91058\n",
      "           1       0.93      0.29      0.45      3428\n",
      "\n",
      "    accuracy                           0.97     94486\n",
      "   macro avg       0.95      0.65      0.72     94486\n",
      "weighted avg       0.97      0.97      0.97     94486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate normal and fraudulent transactions in the train set\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_fraud = X_train[y_train == 1]\n",
    "\n",
    "# Define the number of clusters and the number of samples per cluster\n",
    "n_clusters = 5 # You can change this value\n",
    "n_samples = 100 # You can change this value\n",
    "\n",
    "# Perform k-means clustering on the fraudulent transactions\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X_train_fraud)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create empty lists to store the GAN models and the generated data\n",
    "GAN_models = []\n",
    "generated_data = []\n",
    "\n",
    "# Define some hyperparameters for the GAN models\n",
    "latent_dim = 32 # You can change this value\n",
    "epochs = 50 # You can change this value\n",
    "batch_size = 32 # You can change this value\n",
    "\n",
    "G_l = [[],[],[],[],[]]\n",
    "D_l = [[],[],[],[],[]]\n",
    "Acc = [[],[],[],[],[]]\n",
    "Ep  = [[],[],[],[],[]]\n",
    "\n",
    "# Loop over each cluster\n",
    "for i in range(n_clusters):\n",
    "    # Select the fraudulent transactions belonging to the current cluster\n",
    "    X_cluster = X_train_fraud[labels == i]\n",
    "\n",
    "    # Define the generator model\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(64, input_dim=latent_dim))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    generator.add(Dense(128))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    generator.add(Dense(X.shape[1], activation='tanh'))\n",
    "\n",
    "    # Define the discriminator model\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(128, input_dim=X.shape[1]))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.2))\n",
    "    discriminator.add(Dense(64))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.2))\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "    # Define the combined model (generator + discriminator)\n",
    "    discriminator.trainable = False # Freeze the discriminator when training the generator\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "    # Train the GAN model\n",
    "    for epoch in range(epochs):\n",
    "        # Select a random batch of real data from the current cluster\n",
    "        idx = np.random.randint(0, X_cluster.shape[0], batch_size)\n",
    "        real_data = X_cluster[idx]\n",
    "\n",
    "        # Generate a random batch of noise vectors\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "\n",
    "        # Generate a batch of fake data from the noise vectors\n",
    "        fake_data = generator.predict(noise)\n",
    "\n",
    "        # Concatenate the real and fake data and assign labels\n",
    "        X_data = np.concatenate((real_data, fake_data))\n",
    "        y_data = np.zeros(2*batch_size)\n",
    "        y_data[:batch_size] = 1 # Real data are labeled as 1\n",
    "\n",
    "        # Train the discriminator on the real and fake data\n",
    "        d_loss, d_acc = discriminator.train_on_batch(X_data, y_data)\n",
    "\n",
    "        # Generate another random batch of noise vectors\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "\n",
    "        # Assign labels for the generator as opposite to the discriminator\n",
    "        y_gen = np.ones(batch_size) # Generator tries to fool the discriminator by labeling fake data as 1\n",
    "\n",
    "        # Train the generator on the noise vectors\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "        # Print the losses and the accuracies\n",
    "        print(f'Cluster {i}, Epoch {epoch}, D-Loss: {d_loss}, D-Accuracy: {d_acc}, G-Loss: {g_loss}')\n",
    "        D_l[i].append(d_loss)\n",
    "        G_l[i].append(g_loss)\n",
    "        Acc[i].append(d_acc)\n",
    "        Ep[i].append(epoch)\n",
    "\n",
    "\n",
    "    # Save the GAN model to the list\n",
    "    GAN_models.append(gan)\n",
    "\n",
    "    # Generate n_samples synthetic data from the trained generator and save them to the list\n",
    "    noise = np.random.normal(0, 1, size=(n_samples, latent_dim))\n",
    "    fake_data = generator.predict(noise)\n",
    "    generated_data.append(fake_data)\n",
    "\n",
    "# Concatenate all the generated data from different clusters\n",
    "generated_data = np.vstack(generated_data)\n",
    "\n",
    "# Assign labels for the generated data as fraudulent (1)\n",
    "y_generated = np.ones(generated_data.shape[0])\n",
    "\n",
    "# Concatenate the generated data with the original train set\n",
    "X_train_augmented = np.vstack((X_train, generated_data))\n",
    "y_train_augmented = np.hstack((y_train, y_generated))\n",
    "\n",
    "# Shuffle the augmented train set\n",
    "shuffle_idx = np.random.permutation(X_train_augmented.shape[0])\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]\n",
    "\n",
    "# Define a classifier model (you can use any model you like)\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the classifier on the augmented train set\n",
    "classifier.fit(X_train_augmented, y_train_augmented, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "classes_x = (y_pred > 0.5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, classes_x))\n",
    "print(classification_report(y_test, classes_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
